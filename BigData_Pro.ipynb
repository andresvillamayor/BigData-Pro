{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData-Pro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMk6kCl+LpoayeIPwZDyh1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresvillamayor/BigData-Pro/blob/main/BigData_Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNnvZWOXDS2e"
      },
      "source": [
        "Proyecto de Big Data \n",
        "Andr√©s Villamayor \n",
        "Universidad Comunera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MugxPMXDs0d"
      },
      "source": [
        "#importando librerias\n",
        "import pandas as pd \n",
        "from  google.colab import drive "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpbnIwmBHbrT",
        "outputId": "3a2676f1-c0f9-465c-fb69-fedd81b750ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "#montar mi drive para los archivos \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4a018wJ3sV"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/UCOM-BIGDATA/datatweet-07112020-v1.csv\", sep=\",\" , engine=\"python\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtdAhmhHLDsA",
        "outputId": "e00fa280-0bfe-44e3-fcd4-7d724c40ee5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>Fecha</th>\n",
              "      <th>retweet</th>\n",
              "      <th>favorite</th>\n",
              "      <th>dispositivo</th>\n",
              "      <th>codigo_usuario</th>\n",
              "      <th>alias_de_usuario</th>\n",
              "      <th>nombre_usuario</th>\n",
              "      <th>fecha_de_usuario</th>\n",
              "      <th>descripcion_del_usuario</th>\n",
              "      <th>seguidores_de_usuario</th>\n",
              "      <th>amigos_de_usuario</th>\n",
              "      <th>origen_usuario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1325000220472709120</td>\n",
              "      <td>RT @hoypy: https://t.co/S7JdHyHoLT</td>\n",
              "      <td>2020-11-07 09:00:44</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>151214860</td>\n",
              "      <td>ccentenoc</td>\n",
              "      <td>Carlos Centeno</td>\n",
              "      <td>2010-06-02 22:11:59</td>\n",
              "      <td>Periodista inconformista | Divulgo las investi...</td>\n",
              "      <td>2619</td>\n",
              "      <td>1859</td>\n",
              "      <td>Granada, Andaluc√≠a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1324991828588900352</td>\n",
              "      <td>RT @FabianCosta1: Entre los 10 fallecidos por ...</td>\n",
              "      <td>2020-11-07 08:27:23</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>366739674</td>\n",
              "      <td>inesverag</td>\n",
              "      <td>In√©s Vera</td>\n",
              "      <td>2011-09-02 18:44:16</td>\n",
              "      <td>Propietaria y Conductora de @noticias_atp por ...</td>\n",
              "      <td>209</td>\n",
              "      <td>427</td>\n",
              "      <td>√ëemby-Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1324972016840151042</td>\n",
              "      <td>RT @cinthia_mora: Pablo Herken venci√≥ al COVID...</td>\n",
              "      <td>2020-11-07 07:08:40</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>164378199</td>\n",
              "      <td>AroRojas</td>\n",
              "      <td>AROLITO</td>\n",
              "      <td>2010-07-08 18:45:13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>155</td>\n",
              "      <td>933</td>\n",
              "      <td>Asuncion - Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1324955022631837697</td>\n",
              "      <td>RT @FabianCosta1: Entre los 10 fallecidos por ...</td>\n",
              "      <td>2020-11-07 06:01:08</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>77025881</td>\n",
              "      <td>robcantero</td>\n",
              "      <td>·ñáOB C·ó©·ëéTE·ñáO</td>\n",
              "      <td>2009-09-24 19:47:59</td>\n",
              "      <td>#Fot√≥grafo #SocialMedia #Corresponsal de #Para...</td>\n",
              "      <td>5048</td>\n",
              "      <td>1784</td>\n",
              "      <td>Asunci√≥n - Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1324947182181634048</td>\n",
              "      <td>Entre los 10 fallecidos por covid-19 este vier...</td>\n",
              "      <td>2020-11-07 05:29:59</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>382748730</td>\n",
              "      <td>FabianCosta1</td>\n",
              "      <td>Fabian Costa</td>\n",
              "      <td>2011-09-30 16:25:22</td>\n",
              "      <td>Periodista. Pap√° de tres hermosos peque√±os.\\nD...</td>\n",
              "      <td>7418</td>\n",
              "      <td>905</td>\n",
              "      <td>Lambare Paraguay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...       origen_usuario\n",
              "0  1325000220472709120  ...   Granada, Andaluc√≠a\n",
              "1  1324991828588900352  ...       √ëemby-Paraguay\n",
              "2  1324972016840151042  ...  Asuncion - Paraguay\n",
              "3  1324955022631837697  ...  Asunci√≥n - Paraguay\n",
              "4  1324947182181634048  ...     Lambare Paraguay\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxThER-iLUMW",
        "outputId": "9ef18471-23e0-4476-d512-b95c88ce287d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#usar el texto para (ver el corpus para el analisis de sentimiento)\n",
        "#importamos la libreria NLTK ( Natural Lenguage Tool Kit)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0L-qgxsQeJB"
      },
      "source": [
        "#importa la libreria de soptwords de nltk \n",
        "from nltk.corpus import stopwords\n",
        "# Initialize the stopwords\n",
        "stoplist = stopwords.words('spanish')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0kbPamERI00",
        "outputId": "efc915a2-9af2-41a4-e0ac-6421f4098f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# datos de parada \n",
        "print(stoplist)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'm√°s', 'pero', 'sus', 'le', 'ya', 'o', 'este', 's√≠', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambi√©n', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'm√≠', 'antes', 'algunos', 'qu√©', 'unos', 'yo', 'otro', 'otras', 'otra', '√©l', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 't√∫', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'm√≠o', 'm√≠a', 'm√≠os', 'm√≠as', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'est√°s', 'est√°', 'estamos', 'est√°is', 'est√°n', 'est√©', 'est√©s', 'estemos', 'est√©is', 'est√©n', 'estar√©', 'estar√°s', 'estar√°', 'estaremos', 'estar√©is', 'estar√°n', 'estar√≠a', 'estar√≠as', 'estar√≠amos', 'estar√≠ais', 'estar√≠an', 'estaba', 'estabas', 'est√°bamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuvi√©ramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuvi√©semos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'hab√©is', 'han', 'haya', 'hayas', 'hayamos', 'hay√°is', 'hayan', 'habr√©', 'habr√°s', 'habr√°', 'habremos', 'habr√©is', 'habr√°n', 'habr√≠a', 'habr√≠as', 'habr√≠amos', 'habr√≠ais', 'habr√≠an', 'hab√≠a', 'hab√≠as', 'hab√≠amos', 'hab√≠ais', 'hab√≠an', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubi√©ramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubi√©semos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'se√°is', 'sean', 'ser√©', 'ser√°s', 'ser√°', 'seremos', 'ser√©is', 'ser√°n', 'ser√≠a', 'ser√≠as', 'ser√≠amos', 'ser√≠ais', 'ser√≠an', 'era', 'eras', '√©ramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fu√©ramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fu√©semos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'ten√©is', 'tienen', 'tenga', 'tengas', 'tengamos', 'teng√°is', 'tengan', 'tendr√©', 'tendr√°s', 'tendr√°', 'tendremos', 'tendr√©is', 'tendr√°n', 'tendr√≠a', 'tendr√≠as', 'tendr√≠amos', 'tendr√≠ais', 'tendr√≠an', 'ten√≠a', 'ten√≠as', 'ten√≠amos', 'ten√≠ais', 'ten√≠an', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuvi√©ramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuvi√©semos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dku3cJ2yRV1N",
        "outputId": "084f1d23-82f1-45d8-b4c7-89f42e33660b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creamos un data frame solo con el texto \n",
        "datatexto =  data['texto']\n",
        "datatexto.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   RT @hoypy: https://t.co/S7JdHyHoLT\n",
              "1    RT @FabianCosta1: Entre los 10 fallecidos por ...\n",
              "2    RT @cinthia_mora: Pablo Herken venci√≥ al COVID...\n",
              "3    RT @FabianCosta1: Entre los 10 fallecidos por ...\n",
              "4    Entre los 10 fallecidos por covid-19 este vier...\n",
              "Name: texto, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLwiOOCGXI6W"
      },
      "source": [
        "#funcion de limpiar el texto \n",
        "#librerias\n",
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def limpiar_texto (text):\n",
        "    non_words = list(punctuation)\n",
        "    text = ''.join([c for c in text if c not in non_words])\n",
        "    tokens =  word_tokenize(text)\n",
        "    return tokens"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXqaNFZHban9"
      },
      "source": [
        "#crear una funcion \n",
        "#tokenizar los datos \n",
        "spanish_stopwords = stopwords.words('spanish')\n",
        "def valor_token(tokens):\n",
        "  vector_texto = []\n",
        "  #normalizacion del texto \n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  tokens =  [w for w in tokens if not w in spanish_stopwords]\n",
        "  for item in tokens:\n",
        "        vector_texto.append((item))  \n",
        "  return vector_texto"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXu5yLPfNnG",
        "outputId": "239720ac-9b19-4f97-e1dc-b3428a39577b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Analizar sentimiento del corpus \n",
        "#!pip install spanish-sentiment-analysis\n",
        "#Libreria de Analisis de Sentimiento  https://pypi.org/project/spanish-sentiment-analysis   ( creado por Elliot Hofman 2018)\n",
        "from classifier import SentimentClassifier\n",
        "#crear una funcion \n",
        "def analizar(cadena_texto):\n",
        "  clf = SentimentClassifier()\n",
        "  valor = clf.predict(cadena_texto)\n",
        "  #print (cadena_texto,valor)\n",
        "return valor"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N7mmtEoSEsv",
        "outputId": "95e68ef0-7dbd-4c91-9033-2935b0e49e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "for tweet in datatexto:\n",
        "  datos_limpios = limpiar_texto(tweet)\n",
        "  datos_tokenizados = valor_token (datos_limpios)\n",
        "  #print(datos_tokenizados)\n",
        "  cadena_valor = ' '.join([str(elem) for elem in datos_tokenizados])\n",
        "  #print (cadena_valor)\n",
        "  #analizar sentimiento del corpus \n",
        "  valor = analizar(cadena_valor)\n",
        "\n",
        "\n",
        "#agregar al data frame original el valor del Analisis del Corpus \n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rt hoypy httpstcos7jdhyholt 0.541333260777616\n",
            "rt fabiancosta1 10 fallecidos covid19 viernes beb√© menos a√±o httpstco4gkz9lju4v httpstcogniut‚Ä¶ 0.4039617781831547\n",
            "rt cinthiamora pablo herken venci√≥ covid19 ineram ‚Äú flor instituci√≥n ‚Äù httpstco8jiszgvocc 0.4939643623465431\n",
            "rt fabiancosta1 10 fallecidos covid19 viernes beb√© menos a√±o httpstco4gkz9lju4v httpstcogniut‚Ä¶ 0.4039617781831547\n",
            "10 fallecidos covid19 viernes beb√© menos a√±o httpstco4gkz9lju4v httpstcogniut57law 0.4039617781831547\n",
            "10 fallecidos covid19 viernes beb√© menos a√±o httpstco6l0qpvrjft httpstcobwolhemdrn 0.4039617781831547\n",
            "mientras 5 personas casa blanca incluyendo jefe despacho trump dan positivo covid19 el‚Ä¶ httpstcop2sbolrtsr 0.08036398356532498\n",
            "rt hoypy nacionales pablo herken venci√≥ covid19 ineram ‚Äú flor instituci√≥n ‚Äù httpstcodylwumyhxo 0.6262458917561593\n",
            "verdaderos muertos covid19 httpstcoy8zlzfipcs 0.2692356439862858\n",
            "rt cinthiamora pablo herken venci√≥ covid19 ineram ‚Äú flor instituci√≥n ‚Äù httpstco8jiszgvocc 0.4939643623465431\n",
            "rt medicinauna hoy cero contagios covid19 personal bloque b cl√≠nicas trabajo equipo clave afirman httpstco‚Ä¶ 0.060396697555209246\n",
            "rt pavappy contexto pandemia covid19 travesando nivel global realizamos llamado responsabil‚Ä¶ 0.49680331235728464\n",
            "rt lanacionpy italianos respetar toque queda viernes noche griegos deber√°n pedir permiso por‚Ä¶ 0.7395993623632465\n",
            "rt spinfectologia modelodelquesosuizo combatir pandemia covid19 conceptualizaci√≥n cl√°sica c√≥mo hacer frente‚Ä¶ 0.13784350393762063\n",
            "rt ultimahoracom üî∏el ministerio salud inform√≥ viernes mantiene descenso casos covid19 ocupaci√≥n cama‚Ä¶ 0.22956200897082407\n",
            "rt pavappy contexto pandemia covid19 travesando nivel global realizamos llamado responsabil‚Ä¶ 0.49680331235728464\n",
            "embarazadas covid19 riesgo complicaciones httpstcodgxoxrnjpi trav√©s onlivepy 0.2948772863580909\n",
            "aduvi22 quiere ir miedo covid19 0.32356669414284445\n",
            "aduvi22 hablando ca√≠da persona 60 a√±os amerita visita hospital duele se‚Ä¶ httpstcop5i5ouxxbn 0.5389594999938886\n",
            "httpstco4sbu2imbyr 0.541333260777616\n",
            "rt medicinauna hoy cero contagios covid19 personal bloque b cl√≠nicas trabajo equipo clave afirman httpstco‚Ä¶ 0.060396697555209246\n",
            "httpstcowvsguptusc 0.541333260777616\n",
            "rt lanacionpy ministerio p√∫blico seis meses tiempo seguir investigando extitular petropar patricia samudio‚Ä¶ 0.4501144039353678\n",
            "casos covid19 apuntan descenso ocupaci√≥n camas debajo 80 httpstcoi9lweazr1i v√≠a abcdigital 0.5299638855454109\n",
            "rt hoypy nacionales pablo herken venci√≥ covid19 ineram ‚Äú flor instituci√≥n ‚Äù httpstcodylwumyhxo 0.6262458917561593\n",
            "rt hoypy nacionales pablo herken venci√≥ covid19 ineram ‚Äú flor instituci√≥n ‚Äù httpstcodylwumyhxo 0.6262458917561593\n",
            "covid19 boquer√≥n mejorando httpstcootzu3jte1w v√≠a abcdigital 0.2671793433538093\n",
            "rt desiesquivel ¬°hasta ma√±ana tiempo postular concurso reportajes covid19 iniciativa convocada icfj ijnete‚Ä¶ 0.3766351171977993\n",
            "rt lanacionpy daniel centuri√≥n cuestion√≥ pol√≠ticos plena crisis sanitaria econ√≥mica covid19 hablan proyectos e‚Ä¶ 0.09950844033856249\n",
            "rt lanacionpy italianos respetar toque queda viernes noche griegos deber√°n pedir permiso por‚Ä¶ 0.7395993623632465\n",
            "rt lanacionpy d√≠a 6 noviembre informe ministerio salud p√∫blica bienestar social acerca evoluci√≥n covid19 e‚Ä¶ 0.10087249935508973\n",
            "rt abcdigital ministerio salud inform√≥ encontraron irregularidades protocolos diagn√≥stico covid‚Ä¶ 0.008767063154609385\n",
            "rt lanacionpy coronaviruspy ‚Äú itap√∫a departamento pico invito municipios colaboren medida‚Ä¶ 0.23716694564023458\n",
            "rt hoypy httpstcovzuifsqdzs 0.541333260777616\n",
            "rt hoypy ahora viernes confirmaron 703 casos positivos covid19 junto 10 decesos detalles httpstc‚Ä¶ 0.061234254490146175\n",
            "rt medicinauna hoy cero contagios covid19 personal bloque b cl√≠nicas trabajo equipo clave afirman httpstco‚Ä¶ 0.060396697555209246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-eb8ebeb397c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#print (cadena_valor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#analizar sentimiento del corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0manalizar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadena_valor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-29e45445171e>\u001b[0m in \u001b[0;36manalizar\u001b[0;34m(cadena_texto)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#crear una funcion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalizar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadena_texto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mvalor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadena_texto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcadena_texto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/classifier/sentimentPipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
            "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload_binunicode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_binunicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             raise UnpicklingError(\"BINUNICODE exceeds system's maximum size \"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}