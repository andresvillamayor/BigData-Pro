{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData-Pro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyyBMXmIGOhrXPZp82NNAp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresvillamayor/BigData-Pro/blob/main/BigData_Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNnvZWOXDS2e"
      },
      "source": [
        "Proyecto de Big Data \n",
        "Andrés Villamayor \n",
        "Universidad Comunera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MugxPMXDs0d"
      },
      "source": [
        "#importando librerias\n",
        "import pandas as pd \n",
        "from  google.colab import drive "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpbnIwmBHbrT",
        "outputId": "3a2676f1-c0f9-465c-fb69-fedd81b750ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "#montar mi drive para los archivos \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4a018wJ3sV"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/UCOM-BIGDATA/datatweet-07112020-v1.csv\", sep=\",\" , engine=\"python\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtdAhmhHLDsA",
        "outputId": "e00fa280-0bfe-44e3-fcd4-7d724c40ee5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>Fecha</th>\n",
              "      <th>retweet</th>\n",
              "      <th>favorite</th>\n",
              "      <th>dispositivo</th>\n",
              "      <th>codigo_usuario</th>\n",
              "      <th>alias_de_usuario</th>\n",
              "      <th>nombre_usuario</th>\n",
              "      <th>fecha_de_usuario</th>\n",
              "      <th>descripcion_del_usuario</th>\n",
              "      <th>seguidores_de_usuario</th>\n",
              "      <th>amigos_de_usuario</th>\n",
              "      <th>origen_usuario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1325000220472709120</td>\n",
              "      <td>RT @hoypy: https://t.co/S7JdHyHoLT</td>\n",
              "      <td>2020-11-07 09:00:44</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>151214860</td>\n",
              "      <td>ccentenoc</td>\n",
              "      <td>Carlos Centeno</td>\n",
              "      <td>2010-06-02 22:11:59</td>\n",
              "      <td>Periodista inconformista | Divulgo las investi...</td>\n",
              "      <td>2619</td>\n",
              "      <td>1859</td>\n",
              "      <td>Granada, Andalucía</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1324991828588900352</td>\n",
              "      <td>RT @FabianCosta1: Entre los 10 fallecidos por ...</td>\n",
              "      <td>2020-11-07 08:27:23</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>366739674</td>\n",
              "      <td>inesverag</td>\n",
              "      <td>Inés Vera</td>\n",
              "      <td>2011-09-02 18:44:16</td>\n",
              "      <td>Propietaria y Conductora de @noticias_atp por ...</td>\n",
              "      <td>209</td>\n",
              "      <td>427</td>\n",
              "      <td>Ñemby-Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1324972016840151042</td>\n",
              "      <td>RT @cinthia_mora: Pablo Herken venció al COVID...</td>\n",
              "      <td>2020-11-07 07:08:40</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>164378199</td>\n",
              "      <td>AroRojas</td>\n",
              "      <td>AROLITO</td>\n",
              "      <td>2010-07-08 18:45:13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>155</td>\n",
              "      <td>933</td>\n",
              "      <td>Asuncion - Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1324955022631837697</td>\n",
              "      <td>RT @FabianCosta1: Entre los 10 fallecidos por ...</td>\n",
              "      <td>2020-11-07 06:01:08</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>77025881</td>\n",
              "      <td>robcantero</td>\n",
              "      <td>ᖇOB CᗩᑎTEᖇO</td>\n",
              "      <td>2009-09-24 19:47:59</td>\n",
              "      <td>#Fotógrafo #SocialMedia #Corresponsal de #Para...</td>\n",
              "      <td>5048</td>\n",
              "      <td>1784</td>\n",
              "      <td>Asunción - Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1324947182181634048</td>\n",
              "      <td>Entre los 10 fallecidos por covid-19 este vier...</td>\n",
              "      <td>2020-11-07 05:29:59</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>382748730</td>\n",
              "      <td>FabianCosta1</td>\n",
              "      <td>Fabian Costa</td>\n",
              "      <td>2011-09-30 16:25:22</td>\n",
              "      <td>Periodista. Papá de tres hermosos pequeños.\\nD...</td>\n",
              "      <td>7418</td>\n",
              "      <td>905</td>\n",
              "      <td>Lambare Paraguay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...       origen_usuario\n",
              "0  1325000220472709120  ...   Granada, Andalucía\n",
              "1  1324991828588900352  ...       Ñemby-Paraguay\n",
              "2  1324972016840151042  ...  Asuncion - Paraguay\n",
              "3  1324955022631837697  ...  Asunción - Paraguay\n",
              "4  1324947182181634048  ...     Lambare Paraguay\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxThER-iLUMW",
        "outputId": "9ef18471-23e0-4476-d512-b95c88ce287d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#usar el texto para (ver el corpus para el analisis de sentimiento)\n",
        "#importamos la libreria NLTK ( Natural Lenguage Tool Kit)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0L-qgxsQeJB"
      },
      "source": [
        "#importa la libreria de soptwords de nltk \n",
        "from nltk.corpus import stopwords\n",
        "# Initialize the stopwords\n",
        "stoplist = stopwords.words('spanish')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0kbPamERI00",
        "outputId": "efc915a2-9af2-41a4-e0ac-6421f4098f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# datos de parada \n",
        "print(stoplist)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dku3cJ2yRV1N",
        "outputId": "084f1d23-82f1-45d8-b4c7-89f42e33660b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creamos un data frame solo con el texto \n",
        "datatexto =  data['texto']\n",
        "datatexto.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   RT @hoypy: https://t.co/S7JdHyHoLT\n",
              "1    RT @FabianCosta1: Entre los 10 fallecidos por ...\n",
              "2    RT @cinthia_mora: Pablo Herken venció al COVID...\n",
              "3    RT @FabianCosta1: Entre los 10 fallecidos por ...\n",
              "4    Entre los 10 fallecidos por covid-19 este vier...\n",
              "Name: texto, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLwiOOCGXI6W"
      },
      "source": [
        "#funcion de limpiar el texto \n",
        "#librerias\n",
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def limpiar_texto (text):\n",
        "    non_words = list(punctuation)\n",
        "    text = ''.join([c for c in text if c not in non_words])\n",
        "    tokens =  word_tokenize(text)\n",
        "    return tokens"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXqaNFZHban9"
      },
      "source": [
        "#crear una funcion \n",
        "#tokenizar los datos \n",
        "spanish_stopwords = stopwords.words('spanish')\n",
        "def valor_token(tokens):\n",
        "  vector_texto = []\n",
        "  #normalizacion del texto \n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  tokens =  [w for w in tokens if not w in spanish_stopwords]\n",
        "  for item in tokens:\n",
        "        vector_texto.append((item))  \n",
        "  return vector_texto"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXu5yLPfNnG"
      },
      "source": [
        "# Analizar sentimiento del corpus \n",
        "#!pip install spanish-sentiment-analysis\n",
        "#Libreria de Analisis de Sentimiento  https://pypi.org/project/spanish-sentiment-analysis   ( creado por Elliot Hofman 2018)\n",
        "from classifier import SentimentClassifier\n",
        "#crear una funcion \n",
        "def analizar(cadena_texto):\n",
        "  clf = SentimentClassifier()\n",
        "  valor = clf.predict(cadena_texto)\n",
        "  #print (cadena_texto,valor) \n",
        "  return valor"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N7mmtEoSEsv",
        "outputId": "03298937-c2ca-4a4a-db25-2d8a27be57e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "for tweet in datatexto:\n",
        "  datos_limpios = limpiar_texto(tweet)\n",
        "  datos_tokenizados = valor_token (datos_limpios)\n",
        "  #print(datos_tokenizados)\n",
        "  cadena_valor = ' '.join([str(elem) for elem in datos_tokenizados])\n",
        "  #print (cadena_valor)\n",
        "  #analizar sentimiento del corpus \n",
        "  resultado_valor=[]\n",
        "  valor = analizar(cadena_valor)\n",
        "  resultado_valor.append(valor)  \n",
        "  print (resultado_valor)\n",
        "\n",
        "#agregar al data frame original el valor del Analisis del Corpus \n",
        "df = pd.data\n",
        "df['resultado_valor'] = resultado_valor\n",
        "data.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.541333260777616]\n",
            "[0.4039617781831547]\n",
            "[0.4939643623465431]\n",
            "[0.4039617781831547]\n",
            "[0.4039617781831547]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-52896a6193bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#analizar sentimiento del corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mresultado_valor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mvalor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalizar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadena_valor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mresultado_valor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresultado_valor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-4e2a4660ab38>\u001b[0m in \u001b[0;36manalizar\u001b[0;34m(cadena_texto)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#crear una funcion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalizar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadena_texto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mvalor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadena_texto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#print (cadena_texto,valor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/classifier/sentimentPipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
            "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload_long_binput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_long_binput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative LONG_BINPUT argument\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fWFYVQcqC5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}