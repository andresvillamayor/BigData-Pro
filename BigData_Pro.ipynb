{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData-Pro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2jrfKavPTmO7zH/C0NvFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresvillamayor/BigData-Pro/blob/main/BigData_Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNnvZWOXDS2e"
      },
      "source": [
        "Proyecto de Big Data \n",
        "Andr√©s Villamayor \n",
        "Universidad Comunera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MugxPMXDs0d"
      },
      "source": [
        "#importando librerias\n",
        "import pandas as pd \n",
        "from  google.colab import drive "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpbnIwmBHbrT",
        "outputId": "aecc3c77-94fe-4bad-be96-6e3a3d869808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "#montar mi drive para los archivos \n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV4a018wJ3sV"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/UCOM-BIGDATA/datatweet-07112020-v2.csv\", sep=\",\" , engine=\"python\")"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtdAhmhHLDsA",
        "outputId": "aeaa38c1-8991-4b38-8f3d-04d35d9d4d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>Fecha</th>\n",
              "      <th>retweet</th>\n",
              "      <th>favorite</th>\n",
              "      <th>dispositivo</th>\n",
              "      <th>codigo_usuario</th>\n",
              "      <th>alias_de_usuario</th>\n",
              "      <th>nombre_usuario</th>\n",
              "      <th>fecha_de_usuario</th>\n",
              "      <th>descripcion_del_usuario</th>\n",
              "      <th>seguidores_de_usuario</th>\n",
              "      <th>amigos_de_usuario</th>\n",
              "      <th>origen_usuario</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1325044772231319552</td>\n",
              "      <td>RT @LaNacionPy: üî¥ Seis pa√≠ses, entre ellos Din...</td>\n",
              "      <td>2020-11-07 11:57:46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>280147821</td>\n",
              "      <td>CynthiaLorenaGP</td>\n",
              "      <td>Cynthia Lorena GP</td>\n",
              "      <td>2011-04-10 18:53:02</td>\n",
              "      <td>Abogada y futura Notaria. Olimpista. Lambare√±a...</td>\n",
              "      <td>120</td>\n",
              "      <td>914</td>\n",
              "      <td>Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1325043363574390785</td>\n",
              "      <td>üî¥ Seis pa√≠ses, entre ellos Dinamarca, Espa√±a y...</td>\n",
              "      <td>2020-11-07 11:52:10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>166275230</td>\n",
              "      <td>LaNacionPy</td>\n",
              "      <td>Diario La Naci√≥n</td>\n",
              "      <td>2010-07-13 19:22:08</td>\n",
              "      <td>Informaci√≥n, an√°lisis y opini√≥n hace 25 a√±os.\\...</td>\n",
              "      <td>325301</td>\n",
              "      <td>438</td>\n",
              "      <td>Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1325041977717641216</td>\n",
              "      <td>RT @npyoficial: #Destacado El reporte diario d...</td>\n",
              "      <td>2020-11-07 11:46:40</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>1059586038027468800</td>\n",
              "      <td>alexisdla_</td>\n",
              "      <td>Alexis üëΩ</td>\n",
              "      <td>2018-11-05 23:19:32</td>\n",
              "      <td>ü§∑üèª‚Äç‚ôÇÔ∏è</td>\n",
              "      <td>112</td>\n",
              "      <td>193</td>\n",
              "      <td>Asuncion, Paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1325039205572079616</td>\n",
              "      <td>RT @npyoficial: #Destacado El reporte diario d...</td>\n",
              "      <td>2020-11-07 11:35:39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>44473997</td>\n",
              "      <td>tanaschembori</td>\n",
              "      <td>tana schembori</td>\n",
              "      <td>2009-06-03 22:21:31</td>\n",
              "      <td>teatrera, contadora de historias, mama, herman...</td>\n",
              "      <td>46511</td>\n",
              "      <td>1383</td>\n",
              "      <td>asunci√≥n paraguay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1325039193920311298</td>\n",
              "      <td>#Destacado El reporte diario del covid-19 anun...</td>\n",
              "      <td>2020-11-07 11:35:36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>TweetDeck</td>\n",
              "      <td>93931259</td>\n",
              "      <td>paraguaycom</td>\n",
              "      <td>Paraguay.com</td>\n",
              "      <td>2009-12-01 20:01:00</td>\n",
              "      <td>Noticias de Paraguay y el mundo, minuto a minu...</td>\n",
              "      <td>174141</td>\n",
              "      <td>727</td>\n",
              "      <td>Asunci√≥n, Paraguay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...      origen_usuario\n",
              "0  1325044772231319552  ...            Paraguay\n",
              "1  1325043363574390785  ...            Paraguay\n",
              "2  1325041977717641216  ...  Asuncion, Paraguay\n",
              "3  1325039205572079616  ...   asunci√≥n paraguay\n",
              "4  1325039193920311298  ...  Asunci√≥n, Paraguay\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxThER-iLUMW"
      },
      "source": [
        "#usar el texto para (ver el corpus para el analisis de sentimiento)\n",
        "#importamos la libreria NLTK ( Natural Lenguage Tool Kit)\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0L-qgxsQeJB"
      },
      "source": [
        "#importa la libreria de soptwords de nltk \n",
        "from nltk.corpus import stopwords\n",
        "# Initialize the stopwords\n",
        "stoplist = stopwords.words('spanish')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0kbPamERI00",
        "outputId": "b032aaa8-215d-4e61-9cd3-dcfb1c469523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# datos de parada \n",
        "print(stoplist)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'm√°s', 'pero', 'sus', 'le', 'ya', 'o', 'este', 's√≠', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambi√©n', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'm√≠', 'antes', 'algunos', 'qu√©', 'unos', 'yo', 'otro', 'otras', 'otra', '√©l', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 't√∫', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'm√≠o', 'm√≠a', 'm√≠os', 'm√≠as', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'est√°s', 'est√°', 'estamos', 'est√°is', 'est√°n', 'est√©', 'est√©s', 'estemos', 'est√©is', 'est√©n', 'estar√©', 'estar√°s', 'estar√°', 'estaremos', 'estar√©is', 'estar√°n', 'estar√≠a', 'estar√≠as', 'estar√≠amos', 'estar√≠ais', 'estar√≠an', 'estaba', 'estabas', 'est√°bamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuvi√©ramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuvi√©semos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'hab√©is', 'han', 'haya', 'hayas', 'hayamos', 'hay√°is', 'hayan', 'habr√©', 'habr√°s', 'habr√°', 'habremos', 'habr√©is', 'habr√°n', 'habr√≠a', 'habr√≠as', 'habr√≠amos', 'habr√≠ais', 'habr√≠an', 'hab√≠a', 'hab√≠as', 'hab√≠amos', 'hab√≠ais', 'hab√≠an', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubi√©ramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubi√©semos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'se√°is', 'sean', 'ser√©', 'ser√°s', 'ser√°', 'seremos', 'ser√©is', 'ser√°n', 'ser√≠a', 'ser√≠as', 'ser√≠amos', 'ser√≠ais', 'ser√≠an', 'era', 'eras', '√©ramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fu√©ramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fu√©semos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'ten√©is', 'tienen', 'tenga', 'tengas', 'tengamos', 'teng√°is', 'tengan', 'tendr√©', 'tendr√°s', 'tendr√°', 'tendremos', 'tendr√©is', 'tendr√°n', 'tendr√≠a', 'tendr√≠as', 'tendr√≠amos', 'tendr√≠ais', 'tendr√≠an', 'ten√≠a', 'ten√≠as', 'ten√≠amos', 'ten√≠ais', 'ten√≠an', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuvi√©ramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuvi√©semos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dku3cJ2yRV1N",
        "outputId": "72549b70-1ecb-46e3-b279-8e348c076a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creamos un data frame solo con el texto \n",
        "datatexto =  data['texto']\n",
        "datatexto.head()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    RT @LaNacionPy: üî¥ Seis pa√≠ses, entre ellos Din...\n",
              "1    üî¥ Seis pa√≠ses, entre ellos Dinamarca, Espa√±a y...\n",
              "2    RT @npyoficial: #Destacado El reporte diario d...\n",
              "3    RT @npyoficial: #Destacado El reporte diario d...\n",
              "4    #Destacado El reporte diario del covid-19 anun...\n",
              "Name: texto, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLwiOOCGXI6W"
      },
      "source": [
        "#funcion de limpiar el texto \n",
        "#librerias\n",
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def limpiar_texto (text):\n",
        "    non_words = list(punctuation)\n",
        "    text = ''.join([c for c in text if c not in non_words])\n",
        "    tokens =  word_tokenize(text)\n",
        "    return tokens"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXqaNFZHban9"
      },
      "source": [
        "#crear una funcion \n",
        "#tokenizar los datos \n",
        "spanish_stopwords = stopwords.words('spanish')\n",
        "def valor_token(tokens):\n",
        "  vector_texto = []\n",
        "  #normalizacion del texto \n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  tokens =  [w for w in tokens if not w in spanish_stopwords]\n",
        "  for item in tokens:\n",
        "        vector_texto.append((item))  \n",
        "  return vector_texto"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXu5yLPfNnG"
      },
      "source": [
        "# Analizar sentimiento del corpus \n",
        "#!pip install spanish-sentiment-analysis\n",
        "#Libreria de Analisis de Sentimiento  https://pypi.org/project/spanish-sentiment-analysis   ( creado por Elliot Hofman 2018)\n",
        "from classifier import SentimentClassifier\n",
        "#crear una funcion \n",
        "def analizar(cadena_texto):\n",
        "  clf = SentimentClassifier()\n",
        "  valor = clf.predict(cadena_texto)\n",
        "  #print (cadena_texto,valor) \n",
        "  return valor"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N7mmtEoSEsv",
        "outputId": "c1640c1e-172f-4f5d-ebb4-2d64c303f94b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for tweet in datatexto:\n",
        "  datos_limpios = limpiar_texto(tweet)\n",
        "  datos_tokenizados = valor_token (datos_limpios)\n",
        "  #print(datos_tokenizados)\n",
        "  cadena_valor = ' '.join([str(elem) for elem in datos_tokenizados])\n",
        "  #print (cadena_valor)\n",
        "  #analizar sentimiento del corpus \n",
        "  resultado_valor=[]\n",
        "  valor = analizar(cadena_valor)\n",
        "  resultado_valor.append(valor)  \n",
        "  print (resultado_valor)\n",
        "\n",
        "#agregar al data frame original el valor del Analisis del Corpus \n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20788143176796334]\n",
            "[0.20788143176796334]\n",
            "[0.041255408390936506]\n",
            "[0.041255408390936506]\n",
            "[0.041255408390936506]\n",
            "[0.041255408390936506]\n",
            "[0.449804394751318]\n",
            "[0.4039617781831547]\n",
            "[0.03892627970177291]\n",
            "[0.6262458917561593]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fWFYVQcqC5P",
        "outputId": "ea3ea8de-1e30-48b8-9297-6b90d8961498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "data['Pre'] = resultado_valor"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-a2b54bd015a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pre'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresultado_valor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (10)"
          ]
        }
      ]
    }
  ]
}